{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c9a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sksurv.util import Surv as skSurv\n",
    "from sksurv.metrics import concordance_index_ipcw, cumulative_dynamic_auc, brier_score, integrated_brier_score\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.utils import resample\n",
    "from utils.param_search import *\n",
    "from utils.output_results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84fab9a-2b9e-4f66-9f73-1a956096913f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3700163-2260-424f-9b83-05f5270feeb2",
   "metadata": {},
   "source": [
    "The uncertainty measure used here is the Deep Ensemble method.\n",
    "\n",
    "2 real datasets can be used : \n",
    "- the LungCancerExplorer dataset is a set composed of multiple sources of data\n",
    "- the METABRIC cohort.\n",
    "\n",
    "We apply this method to different types of neural network models :\n",
    "- CoxCC, CoxTime\n",
    "- DeepHit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4612003",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', '-dt', default='Metabric', type=str) #LungCancerExplorer, Metabric\n",
    "parser.add_argument('--name', '-n',type=str, default=\"DeepHit\")#CoxTime, DeepHit, CoxCC \n",
    "parser.add_argument('--plot_mode', '-pm', default=False, action='store_true')\n",
    "parser.add_argument('--timepoints', '-tp',type=str, default=\"fixed\") #fixed, percentiles\n",
    "parser.add_argument('--uncertainty', '-u',type=str, default=\"DeepEnsemble\") #Bootstrap, MCDropout, DeepEnsemble, VAE, BMask\n",
    "config = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc736f2-4aa3-4584-970b-b71e1674743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_res = 'results/'+ config.dataset + \"/\"+config.uncertainty+\"/\"+ config.name+'/'\n",
    "os.makedirs(dir_res, exist_ok=True)\n",
    "\n",
    "dir_data = \"data/\" + config.dataset + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a53a4",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8acca5-f88e-492f-9df6-f6c2a399c930",
   "metadata": {},
   "source": [
    "Missing data are previously handled using the MICE package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af645f01-3b65-477f-b169-1d7f1ca84324",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dir_data+\"DataImputed.csv\")\n",
    "df['id'] = df.index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ea8843-ae36-4deb-9936-f29e64162f04",
   "metadata": {},
   "source": [
    "We list the clinical variables and the genes variables according to the dataset considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442ffb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.dataset == \"Metabric\":\n",
    "    ClinVar =['age',\n",
    "                   'chemotherapy',\n",
    "                   'grade1',\n",
    "                   'grade2',\n",
    "                   'hormonotherapy',\n",
    "                   'N',\n",
    "                   'tumor_size']\n",
    "    ColsLeave = ['chemotherapy',\n",
    "                  'grade1',\n",
    "                  'grade2',\n",
    "                  'id',\n",
    "                  'hormonotherapy',\n",
    "                  'N',\n",
    "                  'status',\n",
    "                  'yy']\n",
    "elif config.dataset == \"LungCancerExplorer\":\n",
    "    ClinVar = ['Pat_Age',\n",
    "                    'Pat_Stage_II',\n",
    "                    'Pat_Stage_III',\n",
    "                    'Pat_Stage_IV',\n",
    "                    'Pat_Stage_I_or_II']\n",
    "    ColsLeave = ['id',\n",
    "                  'Pat_Stage_II',\n",
    "                  'Pat_Stage_III',\n",
    "                  'Pat_Stage_IV',\n",
    "                  'Pat_Stage_I_or_II',\n",
    "                  'status',\n",
    "                  'yy']\n",
    "GenesVar = df.drop(columns = ClinVar + ['id','status','yy'],axis=1).columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24cdc11-18a8-4e46-80a5-ad5b247185c9",
   "metadata": {},
   "source": [
    "The 5 folds of the simple cross-validation are defined and saved beforehand in order to always have the same folds between the different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab18dd7-ef7b-4e50-a16a-0ba330da1ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dir_data+\"folds_1CV.json\") as f:\n",
    "    kfolds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35c428c1-1906-48dd-95bc-3337069aad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[ClinVar+GenesVar+['yy','status','id']].loc[kfolds['train']] \n",
    "df_test = df[ClinVar+GenesVar+['yy','status','id']].loc[kfolds['test']] \n",
    "AllVar = ClinVar+GenesVar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc028482-4009-40cb-81c5-f651c2c1db94",
   "metadata": {},
   "source": [
    "The continuous variable are standardized. The yy variable corresponds to the survival time, the status is the censoring indicator (a value of 0 corresponds to censoring) and the id variable is the id of the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "842d0921-dc7e-407e-9e63-1cfb34bb5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColsStandardize = [col for col in AllVar if col not in ColsLeave] \n",
    "standardize = [([col], StandardScaler()) for col in ColsStandardize]\n",
    "leave = [(col, None) for col in ColsLeave]\n",
    "df_mapper = DataFrameMapper(standardize + leave, df_out=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1416dbd6",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efd5d38",
   "metadata": {},
   "source": [
    "A simple 5-folds cross validation is implemented using the training set to determine the hyperparameters of the neural network models. The optuna package is used to perform the hyperparmeter search. The hyperparameter that are searched are the following:\n",
    "\n",
    "| Hyperparameter | Values |\n",
    "|----------|--------------|\n",
    "| Activation function |  {tanh, relu} |\n",
    "| Batch size |  {8,16,32,64,128} |\n",
    "| Dropout rate |  [0.0,0.3] | \n",
    "|Layers | {1,2,3,4}|\n",
    "|Learning rate|[1e-3, 1e-2]|\n",
    "|Neurons|[4,128]|\n",
    "|Optimizer|{adam, adam_amsgrad, RMSProp, SGDWR}|\n",
    "|PÃ©nalisation L2|[0,0.1]|\n",
    "|Alpha (DeepHit)|[0,1]|\n",
    "|Sigma(DeepHit)|{0.1,0.25,0.5,1,2.5,5,10,100}|\n",
    "|Durations(DeepHit)|{10,50,100,200,400}|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dac7c74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-02-02 11:21:26,679]\u001b[0m A new study created in RDB with name: DeepHit\u001b[0m\n",
      "\u001b[32m[I 2022-02-02 11:23:02,845]\u001b[0m Trial 0 finished with value: 1.5768827438354491 and parameters: {'activation': 'tanh', 'batch_size': 16, 'n_layers': 4, 'learning_rate': 0.002314845462333993, 'neurons': 96, 'optimizer': 'adam_amsgrad', 'l2': 0.042175745590026105, 'dropout': 0.15568239823266364, 'num_durations': 400, 'alpha': 0.4668119737058778, 'sigma': 10}. Best is trial 0 with value: 1.5768827438354491.\u001b[0m\n",
      "\u001b[32m[I 2022-02-02 11:23:49,471]\u001b[0m Trial 1 finished with value: 0.34262646436691285 and parameters: {'activation': 'tanh', 'batch_size': 64, 'n_layers': 1, 'learning_rate': 0.0020370902234228662, 'neurons': 78, 'optimizer': 'adam_amsgrad', 'l2': 0.0678533578408319, 'dropout': 0.2475888391514687, 'num_durations': 10, 'alpha': 0.10008811218478098, 'sigma': 5}. Best is trial 1 with value: 0.34262646436691285.\u001b[0m\n",
      "\u001b[32m[I 2022-02-02 11:24:40,792]\u001b[0m Trial 2 finished with value: 0.9628446817398071 and parameters: {'activation': 'relu', 'batch_size': 64, 'n_layers': 3, 'learning_rate': 0.005952526384394339, 'neurons': 21, 'optimizer': 'adam_amsgrad', 'l2': 0.010403658776266901, 'dropout': 0.2899283230712825, 'num_durations': 200, 'alpha': 0.2786735474952905, 'sigma': 5}. Best is trial 1 with value: 0.34262646436691285.\u001b[0m\n",
      "\u001b[32m[I 2022-02-02 11:25:41,053]\u001b[0m Trial 3 finished with value: 1.0615275859832765 and parameters: {'activation': 'tanh', 'batch_size': 128, 'n_layers': 3, 'learning_rate': 0.00849823977025958, 'neurons': 51, 'optimizer': 'adam_amsgrad', 'l2': 0.06284484643982635, 'dropout': 0.1844903277871602, 'num_durations': 10, 'alpha': 0.7811051960750622, 'sigma': 0.1}. Best is trial 1 with value: 0.34262646436691285.\u001b[0m\n",
      "\u001b[32m[I 2022-02-02 11:26:40,635]\u001b[0m Trial 4 finished with value: 1.1602803468704224 and parameters: {'activation': 'tanh', 'batch_size': 128, 'n_layers': 3, 'learning_rate': 0.003091795920005133, 'neurons': 104, 'optimizer': 'rmsprop', 'l2': 0.07213493303804415, 'dropout': 0.08632240572433315, 'num_durations': 10, 'alpha': 0.8744344964369773, 'sigma': 5}. Best is trial 1 with value: 0.34262646436691285.\u001b[0m\n",
      "\u001b[32m[I 2022-02-02 11:27:20,149]\u001b[0m Trial 5 finished with value: 1.9324970841407776 and parameters: {'activation': 'tanh', 'batch_size': 64, 'n_layers': 3, 'learning_rate': 0.00413967074697736, 'neurons': 10, 'optimizer': 'rmsprop', 'l2': 0.09338253023838597, 'dropout': 0.1086457683218849, 'num_durations': 200, 'alpha': 0.6706787534539572, 'sigma': 2.5}. Best is trial 1 with value: 0.34262646436691285.\u001b[0m\n",
      "\u001b[33m[W 2022-02-02 11:27:24,352]\u001b[0m Trial 6 failed because of the following error: ValueError('Expected more than 1 value per channel when training, got input size torch.Size([1, 12])')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-10-d626110636d2>\", line 9, in <lambda>\n",
      "    study.optimize(lambda trial : objective_net(trial,\n",
      "  File \"C:\\Users\\E_ROBLIN\\Desktop\\these\\Umeasures_nnet\\utils\\param_search.py\", line 83, in objective_net\n",
      "    log = model.fit(x_train,\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torchtuples\\base.py\", line 294, in fit\n",
      "    log = self.fit_dataloader(dataloader, epochs, callbacks, verbose, metrics, val_dataloader)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torchtuples\\base.py\", line 236, in fit_dataloader\n",
      "    self.batch_metrics = self.compute_metrics(data, self.metrics)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torchtuples\\base.py\", line 180, in compute_metrics\n",
      "    out = self.net(*input)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torchtuples\\practical.py\", line 84, in forward\n",
      "    return self.net(input)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torchtuples\\practical.py\", line 61, in forward\n",
      "    input = self.batch_norm(input)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\", line 168, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 2280, in batch_norm\n",
      "    _verify_batch_size(input.size())\n",
      "  File \"C:\\Users\\E_ROBLIN\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\", line 2248, in _verify_batch_size\n",
      "    raise ValueError(\"Expected more than 1 value per channel when training, got input size {}\".format(size))\n",
      "ValueError: Expected more than 1 value per channel when training, got input size torch.Size([1, 12])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size torch.Size([1, 12])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d626110636d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m study.optimize(lambda trial : objective_net(trial,\n\u001b[0m\u001b[0;32m     10\u001b[0m                                             \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                             \u001b[0mdf_mapper\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    398\u001b[0m             )\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-d626110636d2>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m study.optimize(lambda trial : objective_net(trial,\n\u001b[0m\u001b[0;32m     10\u001b[0m                                             \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                             \u001b[0mdf_mapper\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\these\\Umeasures_nnet\\utils\\param_search.py\u001b[0m in \u001b[0;36mobjective_net\u001b[1;34m(trial, df, df_mapper, dir_res, config)\u001b[0m\n\u001b[0;32m     81\u001b[0m                                      \u001b[0min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                                      labtrans)\n\u001b[1;32m---> 83\u001b[1;33m         log = model.fit(x_train, \n\u001b[0m\u001b[0;32m     84\u001b[0m                         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                         \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtuples\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, input, target, batch_size, epochs, callbacks, verbose, num_workers, shuffle, metrics, val_data, val_batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m             )\n\u001b[1;32m--> 294\u001b[1;33m         \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtuples\\base.py\u001b[0m in \u001b[0;36mfit_dataloader\u001b[1;34m(self, dataloader, epochs, callbacks, verbose, metrics, val_dataloader)\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_metrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtuples\\base.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[1;34m(self, data, metrics)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuplefy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtuples\\practical.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torchtuples\\practical.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \"\"\"\n\u001b[1;32m--> 168\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2278\u001b[0m         )\n\u001b[0;32m   2279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2280\u001b[1;33m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2282\u001b[0m     return torch.batch_norm(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_verify_batch_size\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m   2246\u001b[0m         \u001b[0msize_prods\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2247\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_prods\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2248\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected more than 1 value per channel when training, got input size {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size torch.Size([1, 12])"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(study_name = config.name, \n",
    "                            storage = 'sqlite:///'+dir_res+config.name+'.db',\n",
    "                            sampler=sampler, \n",
    "                            direction='minimize', \n",
    "                            load_if_exists=True)\n",
    "\n",
    "\n",
    "study.optimize(lambda trial : objective_net(trial,\n",
    "                                            df_train,\n",
    "                                            df_mapper,\n",
    "                                            dir_res,\n",
    "                                            config), \n",
    "                                           n_trials=200)\n",
    "trial = study.best_trial\n",
    "outer_loop = pd.DataFrame([trial.params])\n",
    "outer_loop.to_csv(dir_res+'best_param.csv', sep = ';', index = False, header = True)\n",
    "df_results = study.trials_dataframe()\n",
    "df_results.to_csv(dir_res+'trials_dataframe.csv', sep = ';', header = True)\n",
    "\n",
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.write_image(dir_res+\"optim_history.png\")\n",
    "fig2 = optuna.visualization.plot_slice(study)\n",
    "fig2.write_image(dir_res+\"parameters_history.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d00bdd",
   "metadata": {},
   "source": [
    "# Uncertainty Measure using DeepEnsemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1fe262",
   "metadata": {},
   "source": [
    "We build the model using always the same hyperparameters that were selected by cross validaton. Then, the model is trained M times, randomly initializing the weights each time. The training set is randomly shuffled. The training criterion is the loss. M predictions per point of the test set are outputed. This is the method called [DeepEnsemble](https://proceedings.neurips.cc/paper/2017/file/9ef2ed4b7fd2c810847ffa5fa85bce38-Paper.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176b06be-62ff-4d68-88f3-3e1ee5f66ebd",
   "metadata": {},
   "source": [
    "We load the hyperparameters selected previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1311bd0-b687-424d-a8d2-cddaad73ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_loop = pd.read_csv(dir_res+'best_param.csv', sep = ';')\n",
    "config.acti_func = outer_loop['activation'][0]\n",
    "config.batch_size = outer_loop['batch_size'][0]\n",
    "config.dr = outer_loop['dropout'][0]\n",
    "config.layers = outer_loop['n_layers'][0]\n",
    "config.lr  = outer_loop['learning_rate'][0]\n",
    "config.neurons = outer_loop['neurons'][0]\n",
    "config.optim = outer_loop['optimizer'][0]\n",
    "config.pen_l2 = outer_loop['l2'][0]\n",
    "\n",
    "if config.name==\"DeepHit\":\n",
    "    config.alpha = outer_loop['alpha'][0] \n",
    "    config.sigma = outer_loop['sigma'][0]\n",
    "    config.num_durations = outer_loop['num_durations'][0]\n",
    "    labtrans = DeepHitSingle.label_transform(config.num_durations)\n",
    "elif config.name==\"CoxTime\":\n",
    "    labtrans = CoxTime.label_transform()\n",
    "else:\n",
    "    labtrans=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2555a-a253-484b-a969-c344851062df",
   "metadata": {},
   "source": [
    "We define the number of repetitions M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04834480-11a6-45f2-84ad-240eff12ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "M=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bbae4e-8b7f-433b-afb4-731492bd8475",
   "metadata": {},
   "source": [
    "We sample 20\\% of the train set and define it as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51bcaf-5311-4f4c-a571-731a2fe90ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_train.sample(frac=0.2, random_state = 1234)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "df_train = df_mapper.fit_transform(df_train)\n",
    "df_val = df_mapper.transform(df_val).astype('float32')\n",
    "df_test = df_mapper.transform(df_test).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df603655-130a-41df-85f2-9b60d9e83a8f",
   "metadata": {},
   "source": [
    "If the timepoints are defined as percentiles, the results are outputed at the percentiles of survival times. If the timepoints are deifned as fixed, teh results are outputed at specific times.\n",
    "\n",
    "For the breast cancer dataset, the fixed timepoints used are at 5 and 10 years. For the LungCancerExplorer, we output the measures at 2 and 5 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd379389-bd63-4965-a528-8cb4c1274a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.timepoints == \"percentiles\":\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(np.array(df_train['yy']), np.array(df_train['status']))\n",
    "    time_grid = np.array(kmf.percentile(np.linspace(0.9, 0.1, 9)).iloc[:,0])\n",
    "elif config.timepoints == \"fixed\":\n",
    "    if config.dataset == \"Metabric\":\n",
    "        time_grid = [2,5]\n",
    "    elif config.dataset == \"LungCancerExplorer\":\n",
    "        time_grid = [24,60]\n",
    "    else:\n",
    "        time_grid = [0.5,1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d66dc-5d68-4aab-9571-7f4a5ad46064",
   "metadata": {},
   "source": [
    "We define x and y for the train set, the validation set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce58c3-adce-40be-bd56-f1905e36dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(df_train.drop(['yy','status','id'], axis=1)).astype('float32')\n",
    "x_val = np.array(df_val.drop(['yy','status','id'], axis=1)).astype('float32')\n",
    "x_test = np.array(df_test.drop(['yy','status','id'], axis=1)).astype('float32')\n",
    "y_train = (df_train['yy'].values, df_train['status'].values)\n",
    "y_val = (df_val['yy'].values, df_val['status'].values)\n",
    "y_test = (df_test['yy'].values, df_test['status'].values)\n",
    "    \n",
    "if labtrans !=\"\":\n",
    "    y_train = labtrans.fit_transform(*y_train)\n",
    "    y_val = labtrans.transform(*y_val)\n",
    "\n",
    "val = (x_val, y_val)\n",
    "in_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed44946-8add-4b32-9ae5-2da801bb8f9c",
   "metadata": {},
   "source": [
    "We compute the Concordance Index (CAll), the Brier Score (BSAll) and the survival predictions for all the patients of the test set (PredAll) for each timepoint of the time grid previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2ae23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CAll = pd.DataFrame()\n",
    "BSAll = pd.DataFrame()\n",
    "PredAll = []\n",
    "measures = pd.DataFrame()\n",
    "\n",
    "for j in range(M):\n",
    "    print(j)\n",
    "    model,callbacks = build_model_net(config,\n",
    "                                  in_features,\n",
    "                                  labtrans)\n",
    "    log = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    int(config.batch_size),\n",
    "                    epochs = 500, \n",
    "                    callbacks = callbacks,\n",
    "                    verbose = False,\n",
    "                    val_data = val,\n",
    "                   shuffle = True)\n",
    "\n",
    "    if config.name in [\"CoxCC\",\"CoxTime\"]:\n",
    "        _ = model.compute_baseline_hazards()\n",
    "        surv = model.predict_surv_df(x_test)\n",
    "    elif config.name == \"DeepHit\":\n",
    "         surv = model.interpolate(10).predict_surv_df(x_test)\n",
    "\n",
    "    data_train = skSurv.from_arrays(event=df_train['status'], time=df_train['yy'])\n",
    "    data_test = skSurv.from_arrays(event=df_test['status'], time=df_test['yy'])\n",
    "    CAll[j] = [concordance_index_ipcw(data_train, data_test, np.array(-determine_surv_prob(surv,t)),t)[0] for t in time_grid]\n",
    "    BSAll[j] = [brier_score(data_train, data_test, np.array(-determine_surv_prob(surv,t)),t)[1][0] for t in time_grid]\n",
    "    preds = np.asarray([determine_surv_prob(surv,t) for t in time_grid])\n",
    "    PredAll.append(preds)  \n",
    "    del model \n",
    "    del log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e34ccc-8859-4c92-8eb9-fe49b763a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures['C'] = CAll.mean(axis=1)\n",
    "measures['BS'] = BSAll.mean(axis=1)\n",
    "measures['Time'] = time_grid\n",
    "measures.to_csv(dir_res+'measures_'+config.name+'.csv', sep = ';', header = True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23f3ad-2273-4d71-9efd-8be9e69a85e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d274dc56-a3a5-4e5e-9bd8-3a4ad37a4e97",
   "metadata": {},
   "source": [
    "We output survival prediction intervals for a certain number of patients (n_pat) for each timepoint of the timegrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46708e20-3ea2-4de7-89d7-ebe2847218e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pat = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550f32d-6fa6-44f1-8166-b46a077391af",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(4893)\n",
    "patients_test = random.sample(list(df_test['id']),n_pat)\n",
    "ResPat = []\n",
    "for t in range (len(time_grid)):\n",
    "    ResTime = pd.DataFrame([PredAll[l][t] for l in range(M)]).T\n",
    "    for i in patients_test:\n",
    "        ResTime.index = df_test['id']\n",
    "        ic = output_ic(ResTime.loc[i,:],0.95)\n",
    "        values = df_test.loc[:,['status','yy','id']][df_test['id']==i]\n",
    "        ResPat.append(values.values.tolist()[0]+list(ic))\n",
    "ResPat = pd.DataFrame(ResPat)\n",
    "ResPat.columns = ['status','yy','id','IClow','ICmean','IChigh']\n",
    "ResPat[\"Time\"] = np.repeat(time_grid,n_pat)\n",
    "ResPat.to_csv(dir_res+\"surv_intervals.csv\", sep=';', header = True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa43a8-f1a2-4b65-a74c-89c904794383",
   "metadata": {},
   "outputs": [],
   "source": [
    "ResPat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
