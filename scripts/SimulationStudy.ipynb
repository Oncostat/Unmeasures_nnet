{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sksurv.util import Surv as skSurv\n",
    "from sksurv.metrics import concordance_index_ipcw, cumulative_dynamic_auc, brier_score, integrated_brier_score\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.utils import resample\n",
    "from utils.param_search import *\n",
    "from utils.output_results import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used here is the simulation dataset. \n",
    "\n",
    "The uncertainty measures that are available are : MCDropout, DeepEnsemble, VAEUnc, BMask, Bootstrap. Here, we apply the bootstrap method. The other methods can be applied as presented in the other scripts, just by changing the dataset argument to \"Simulation\".\n",
    "\n",
    "We apply this method to different types of neural network models :\n",
    "- CoxCC, CoxTime\n",
    "- DeepHit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', '-dt', default='Simulation', type=str) \n",
    "parser.add_argument('--plot_mode', '-pm', default=True, action='store_true')\n",
    "parser.add_argument('--name', '-n',type=str, default=\"DeepHit\") #CoxTime, DeepHit, CoxCC \n",
    "parser.add_argument('--uncertainty', '-u',type=str, default=\"Bootstrap\") #Bootstrap, MCDropout, DeepEnsemble, VAE, BMask\n",
    "parser.add_argument('--timepoints', '-tp',type=str, default=\"fixed\")\n",
    "config = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_res = 'results/'+ config.dataset + \"/\"+config.uncertainty+\"/\"+ config.name+'/'\n",
    "os.makedirs(dir_res, exist_ok=True)\n",
    "dir_data = 'data'+'/'+config.dataset + \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into train and test sets beforehand. As the data is simulated, it is possible to output the true value of survival times: it is stored in the st_test file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(dir_data+\"sim_train.csv\")\n",
    "df_test = pd.read_csv(dir_data+\"sim_test.csv\")\n",
    "st_test = pd.read_csv(dir_data+\"st_test.csv\").T\n",
    "st_test.index = st_test.index.astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated data is composed of continous variables (the X variables) and a binary variable (the Z variable). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ContVar = ['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10']\n",
    "CatVar = ['Z1']\n",
    "AllVar = ContVar+CatVar+['yy', 'status','id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The continuous variable are standardized. The yy variable corresponds to the survival time, the status is the censoring indicator (a value of 0 corresponds to censoring) and the id variable is the id of the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize = [([col], StandardScaler()) for col in ContVar]\n",
    "leave = [(col, None) for col in ['yy', 'status','id']+CatVar]\n",
    "df_mapper = DataFrameMapper(standardize + leave, df_out=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and Hyperparameters Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple 5-folds cross validation is implemented using the training set to determine the hyperparameters of the neural network models. The optuna package is used to perform the hyperparmeter search. The hyperparameter that are searched are the following:\n",
    "\n",
    "| Hyperparameter | Values |\n",
    "|----------|--------------|\n",
    "| Activation function |  {tanh, relu} |\n",
    "| Batch size |  {8,16,32,64,128} |\n",
    "| Dropout rate |  [0.0,0.3] | \n",
    "|Layers | {1,2,3,4}|\n",
    "|Learning rate|[1e-3, 1e-2]|\n",
    "|Neurons|[4,128]|\n",
    "|Optimizer|{adam, adam_amsgrad, RMSProp, SGDWR}|\n",
    "|PÃ©nalisation L2|[0,0.1]|\n",
    "|Alpha (DeepHit)|[0,1]|\n",
    "|Sigma(DeepHit)|{0.1,0.25,0.5,1,2.5,5,10,100}|\n",
    "|Durations(DeepHit)|{10,50,100,200,400}|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(study_name = config.name, \n",
    "                            storage = 'sqlite:///'+dir_res+config.name+ '.db',\n",
    "                            sampler=sampler, \n",
    "                            direction='minimize', \n",
    "                            load_if_exists=True)\n",
    "\n",
    "study.optimize(lambda trial : objective_net(trial,\n",
    "                                            df_train,\n",
    "                                            df_mapper,\n",
    "                                            dir_res,\n",
    "                                            config), \n",
    "               n_trials=2)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "outer_loop = pd.DataFrame([trial.params])\n",
    "print(\"  Value: \", trial.value)\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n",
    "print(study.trials_dataframe())\n",
    "\n",
    "outer_loop.to_csv(dir_res + 'best_param.csv', sep = ';', index = False, header = True)\n",
    "df_results = study.trials_dataframe()\n",
    "df_results.to_csv(dir_res + 'trials_dataframe.csv', sep = ';', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty Measure using Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build the model using always the same hyperparameters that were selected by cross validaton. We sample with replacement data from the training set.  Then, the model is trained on this  bootstraped dataset. We repeat the sampling M times, obtaining M predictions per point of the test set. This is the method called [Bootstrap](https://www.jstor.org/stable/2958830)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the hyperparameters selected previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_loop = pd.read_csv(dir_res+'best_param.csv', sep = ';')\n",
    "config.acti_func = outer_loop['activation'][0]\n",
    "config.batch_size = outer_loop['batch_size'][0]\n",
    "config.dr = outer_loop['dropout'][0]\n",
    "config.layers = outer_loop['n_layers'][0]\n",
    "config.lr  = outer_loop['learning_rate'][0]\n",
    "config.neurons = outer_loop['neurons'][0]\n",
    "config.optim = outer_loop['optimizer'][0]\n",
    "config.pen_l2 = outer_loop['l2'][0]\n",
    "\n",
    "if config.name==\"DeepHit\":\n",
    "    config.alpha = outer_loop['alpha'][0] \n",
    "    config.sigma = outer_loop['sigma'][0]\n",
    "    config.num_durations = outer_loop['num_durations'][0]\n",
    "    labtrans = DeepHitSingle.label_transform(config.num_durations)\n",
    "elif config.name==\"CoxTime\":\n",
    "    labtrans = CoxTime.label_transform()\n",
    "else:\n",
    "    labtrans=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the number of repetitions, M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.timepoints == \"percentiles\":\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(np.array(df_train['yy']), np.array(df_train['status']))\n",
    "    time_grid = np.array(kmf.percentile(np.linspace(0.9, 0.1, 9)).iloc[:,0])\n",
    "elif config.timepoints == \"fixed\":\n",
    "    if config.dataset == \"Metabric\":\n",
    "        time_grid = [2,5]\n",
    "    elif config.dataset == \"LungCancerExplorer\":\n",
    "        time_grid = [24,60]\n",
    "    else:\n",
    "        time_grid = [0.5,1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the Concordance Index (C-index), the Oracle C-index, the Bias, the Oracle Bias, and the survival predictions for the model at the timepoints of the time grid previously defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CAll = pd.DataFrame()\n",
    "COrAll = pd.DataFrame()\n",
    "BSAll = pd.DataFrame()\n",
    "BSOrAll = pd.DataFrame()\n",
    "PredAll = []\n",
    "measures = pd.DataFrame()\n",
    "\n",
    "for j in range(M):\n",
    "    print(j)\n",
    "    \n",
    "    #Bootstrap of the train set and split into validation and train set\n",
    "    df_trainb = df_train.iloc[resample(df_train.index, replace=True, n_samples=len(df_train),random_state=j)]\n",
    "    df_valb = df_trainb.sample(frac=0.2, random_state = j)\n",
    "    df_trainb = df_trainb.drop(df_valb.index)\n",
    "\n",
    "    df_trainb = df_mapper.fit_transform(df_trainb)\n",
    "    df_valb = df_mapper.transform(df_valb).astype('float32')\n",
    "    df_test = df_mapper.transform(df_test).astype('float32')\n",
    "\n",
    "    x_train = np.array(df_trainb.drop(['yy','status','id'], axis=1)).astype('float32')\n",
    "    x_val = np.array(df_valb.drop(['yy','status','id'], axis=1)).astype('float32')\n",
    "    x_test = np.array(df_test.drop(['yy','status','id'], axis=1)).astype('float32')\n",
    "    y_train = (df_trainb['yy'].values, df_trainb['status'].values)\n",
    "    y_val = (df_valb['yy'].values, df_valb['status'].values)\n",
    "    y_test = (df_test['yy'].values, df_test['status'].values)\n",
    "\n",
    "    if labtrans !=\"\":\n",
    "        y_train = labtrans.fit_transform(*y_train)\n",
    "        y_val = labtrans.transform(*y_val)\n",
    "\n",
    "    val = tt.tuplefy(x_val, y_val)\n",
    "\n",
    "    in_features = x_train.shape[1]\n",
    "    model,callbacks = build_model_net(config,in_features,labtrans)\n",
    "\n",
    "    log = model.fit(x_train, \n",
    "                y_train, \n",
    "                int(config.batch_size),\n",
    "                epochs = 500, \n",
    "                callbacks = callbacks,\n",
    "                verbose = False,\n",
    "                val_data = val,\n",
    "                shuffle=True)\n",
    "    \n",
    "    #Output of the survival probabilities\n",
    "    if config.name in [\"CoxCC\",\"CoxTime\"]:\n",
    "        _ = model.compute_baseline_hazards()\n",
    "        surv = model.predict_surv_df(x_test)\n",
    "    elif config.name == \"DeepHit\":\n",
    "         surv = model.interpolate(10).predict_surv_df(x_test)\n",
    "\n",
    "    #Output of the evaluation measures on the test set at predifined time points\n",
    "    data_train = skSurv.from_arrays(event=df_trainb['status'], time=df_trainb['yy'])\n",
    "    data_test = skSurv.from_arrays(event=df_test['status'], time=df_test['yy'])\n",
    "    CAll[j] = [concordance_index_ipcw(data_train, data_test, np.array(-determine_surv_prob(surv,t)),t)[0] for t in time_grid]\n",
    "    BSAll[j] = [brier_score(data_train, data_test, np.array(-determine_surv_prob(surv,t)),t)[1][0] for t in time_grid]\n",
    "    Pred = np.asarray([determine_surv_prob(surv,t) for t in time_grid])\n",
    "    PredAll.append(Pred)\n",
    "    BSOrAll[j] = [brier_score(data_train, data_test, np.array(-determine_surv_prob(st_test,t)),t)[1][0] for t in time_grid]     \n",
    "    COrAll[j] = [concordance_index_ipcw(data_train, data_test, np.array(-determine_surv_prob(st_test,t)),t)[0] for t in time_grid]     \n",
    "\n",
    "    del model \n",
    "    del log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the coverage rate, the level of confidence is $\\alpha = 0.95$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures['C'] = CAll.mean(axis=1)\n",
    "measures['C_Oracle'] = COrAll.mean(axis=1)\n",
    "measures['BS'] = BSAll.mean(axis=1)\n",
    "measures['BS_Oracle'] = BSOrAll.mean(axis=1)\n",
    "\n",
    "res_all = np.empty((M,len(time_grid)))\n",
    "for m in range(M):\n",
    "    res_all[m,] = [np.mean(PredAll[m][t]) for t in range(len(time_grid))]\n",
    "\n",
    "cr = []\n",
    "BNAll = pd.DataFrame()\n",
    "alpha = 0.95\n",
    "for t in range (len(time_grid)):\n",
    "    res_time = pd.DataFrame([PredAll[l][t] for l in range(M)]).T\n",
    "    cr.append(output_cr(res_time,st_test,time_grid[t],0.95))\n",
    "    BNAll[str(time_grid[t])] = np.mean(pd.DataFrame([PredAll[l][t]-determine_surv_prob(st_test,time_grid[t]) for l in range(M)]).T)\n",
    "measures['Bias_id'] = np.array(BNAll.mean())\n",
    "measures['Coverage'] = cr\n",
    "measures['Time'] = time_grid\n",
    "measures.to_csv(dir_res+'measures_'+config.name+'.csv', sep = ';', header = True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
